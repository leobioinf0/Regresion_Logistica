---
title: 'Regresión Logística surgery'
author: "Leonardo Madsen"
date: "15/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lmtest)
library(plotly)
library(ResourceSelection)
library(car)
library(ROCR)
library(MASS)
```
# Actividad final tema 4: Regresión Logística 

El objetivo es investigar la influencia de posibles variables explicativas en el riesgo de complicaciones post-operatorias en pacientes con problemas pulmonares. Para ello se pide analizar los df usando un modelo logístico adecuado.

df: surgery.txt Variables explicativas: 

• age: Edad del paciente en años

• surgtype: Tipo de cirugía (1= Orthopedic, 2= Gynecological, 3= Abdominal) 

• blocking: Agente bloqueante neuromuscular (1= Pancuronium (P), 2= Vecuronium (V), 3= Atracurium (A)) 

• longact: Agente blanqueante neuromuscular codificado en función de la actividad a largo plazo (0= No (V,A), 1= Si (P), (ver codificación de la variable anterior)

• duration: Duración de la operación en minutos 

• tofratio: La razón T4/T1 en un test de estimulación train − of − four (TOF)

*Variable respuesta:* Y =complicación: Â ¿El paciente experimenta complicación pulmonar? 0: No, 1: Si.

Fuente: Regression with Linear Predictors, Andersen, Per Kragh, Skovgaard, Lene Theil, Springer (2010)
```{r}
df<- read.table("surgery.txt")
head(df)
```

```{r}
df<- read.table("surgery.txt")
df$surgtype = factor(df$surgtype, labels = c("Orthopedic","Gynecological", "Abdominal"))
df$blocking = factor(df$blocking, labels = c("Pancuronium","Vecuronium", "Atracurium"))
df$longact = factor(df$longact, labels = c("No","Si"))
df$complication = factor(df$complication, labels = c("No","Si"))
head(df)
```


##  Seleccionar aleatoriamente el conjunto de entrenamiento. El 80 % de los df serán considerados para construir el modelo (training set). El resto de df 20 % (test set) sería considerado en la posterior evaluación del modelo y debe ser ignorado en la primera parte del estudio, es decir, no tener en cuenta en la construcción del modelo.

```{r}
set.seed(101) # semilla 

sample <- sample.int(n = nrow(df), size = floor(.80*nrow(df)), replace = F)
train <- df[sample, ]
test  <- df[-sample, ]
```




##  Usar un procedimiento secuencial para construir un modelo de regresión logística que permita explicar la variable respuesta a partir de la información dada por las variables explicativas.



Dado que la variable 'longact' depende de 'blocking' primero comprobamos si esta ultima es conveniente meterla en el modelo. Tambien comentar que no centro la edad ya que he probado a hacerlo y proporciona los mismos resultados.

```{r}
summary(glm(complication~ age+surgtype+blocking+duration+tofratio, family = binomial, data=df))
```
Vemos como ningunos de los niveles de 'Blocking' es significativo por lo que no entraria en el mdelo y por tanto la variable 'longact' tampoco lo haria.


```{r}
modelo= glm(complication~ age+surgtype+blocking+duration+tofratio, family = binomial, data=df)
modelo1=step(modelo)
summary(modelo1)
```
Parece que el valor de 'surgtype'= 2 no es significativo habria que hacer un estudio un poco mas incisivo en este typo de variable que dada su naturaleza es una de las variable de interes y que habria que saber como es su interacion con la variable 'complication' dado que el estudio se basa en el post operatorio y sus posibles complicaciones.


Comparamos los valores 'surgtype'= 1 y 'surgtype'= 2. 

```{r}
str(df)
```


```{r}
summary(glm(complication~ age+surgtype+duration+tofratio, subset=which(surgtype==c("Orthopedic","Gynecological")), family = binomial, data=df))
```

El modelo no seria adecuado. y las complicaciones dependerian de otras cosas.

Probamo con 'surgtype'= 1 y 'surgtype'= 3. 

Como veiamos en el modelo incial  'surgtype'= 3 si es significativa lo de lo que podemos deducir que las operaciones tipo 1 y 2 podrian tener efecto parecido en la varaible 'complications'

Probamos un modelo con  'surgtype'= 2 y 'surgtype'= 3. 


Como podemos ver si no se tuviese en cuenta el tipo de cirugia 1  el modelo  resultante pasaria a desechar la variable 'tofratio' que sabes que era muy relevante en el modelo por las primeras impreciones dadas por la funcion step.


En conclusion dado que el estudio es sobre el post-operatorio no tendria sentido no tener en cuenta el tipo de cirugia, cierto es que parece que el tipo 2 (Gynecological), no parece ser significativo para el modelo el estudio precisa de ella para no desviarse del tema.


Coefficients:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept) -5.544673   1.387633  -3.996 6.45e-05 ***
age          0.042318   0.011233   3.767 0.000165 ***
surgtype2    0.508743   0.654573   0.777 0.437033    
surgtype3    2.079119   0.485171   4.285 1.82e-05 ***
duration     0.005823   0.002556   2.278 0.022734 *  
tofratio    -2.304075   1.138304  -2.024 0.042957 * 

Nuestro modelo final es este, como podemos observar la variables 'tofratio' es la unica protectora por tanto a mayoers valores de test de estimulacion menor robabilidad de sufrir complicaciones. 
La esdad es 







### Otras forma:

```{r}

modelo.full <-glm(complication~ age+surgtype+blocking+duration+tofratio+longact, data = df,family = binomial)
modelo.inicial <-glm(complication ~ 1, data = df, family = binomial)
modelo.stp <-stepAIC(modelo.inicial, scope =list(upper = modelo.full), direction = "both")
```

```{r}
summary(modelo.stp)
```

Como podemos ver con la funcion StepAIC podemos secuenciar la forma de encontrar el mejor modelo. 



##  Estudio de la bondad de ajuste. Se requiere una explicación de los resultados obtenidos en los siguientes apartados: 
### a) Contraste de regresión. Resolver mediante el test de razón de verosimilitudes 

```{r}
Anova(modelo1)
```


### b) Contraste de regresión. Resolver mediante el test de Hosmer-Lemeshow.

```{r}
hosmerlem <-function(y, yhat, g = 10){
  cutyhat1 =cut(yhat, breaks =quantile(yhat, probs =seq(0, 1, 1/g)), include.lowest = TRUE)
  obs =xtabs(cbind(1 - y, y) ~ cutyhat1)
  expect =xtabs(cbind(1 - yhat, yhat) ~ cutyhat1)
  chisq.C =sum((obs - expect)^2/expect)
  P.C = 1 -pchisq(chisq.C, g - 2)
  cutyhat2 =cut(yhat, breaks = g, include.lowest = TRUE)
  obs =xtabs(cbind(1 - y, y) ~ cutyhat2)
  expect =xtabs(cbind(1 - yhat, yhat) ~ cutyhat2)
  chisq.H =sum((obs - expect)^2/expect)
  P.H = 1 -pchisq(chisq.H, g - 2)
  res <-data.frame(c(chisq.C, P.C),c(chisq.H, P.H))
  colnames(res) <-c("Hosmer-Lemeshow C statistic", "Hosmer-Lemeshow H statistic")
  rownames(res) <-c("X-squared", "p.value")
  return(res)
  }
```
```{r}
hosmerlem(df$complication,fitted.values(modelo1))
```
 Con un p-valor tan alto podemos aceptar la hipotesis nula de que el modelo se ajusta a los df

### c) Calcular el coeficiente $R^{2}$ de Nagelkerke. 

```{r}
LR <- modelo1$null.deviance - modelo1$deviance
N <-sum(weights(modelo1))  
RsqrCN <- 1 -exp(-LR/N)
L0.adj <-exp(-modelo1$null.deviance/N)
RsqrNal <- RsqrCN/(1 - L0.adj)
RsqrNal
```

Pese a que globalmente el modelo se ajusta a los df parece que no tiene un buen ajuste.
```{r}
```



### d) Construir la curva ROC y calcular el área bajo la curva.
```{r}
pred <-prediction(fitted.values(modelo1), df$complication)
```

```{r}
# auc : Area under curve
AUC <-performance(pred, "auc")
perf2 <-performance(pred, "tpr", "fpr")
plot(perf2, colorize = TRUE)
abline(a = 0, b = 1)
text(0.4, 0.6,paste(AUC@y.name, "\n",round(unlist(AUC@y.values), 3)), cex = 0.7)
```


### e) Obtener el punto de corte óptimo, $p_{opt}$ 
```{r}
#pred <-prediction(fitted.values(modelo1), df$complication)
perf1 <-performance(pred, measure = "acc")
# el punto de corte que maximiza'acc'es
(posicion.max <-sapply(perf1@y.values, which.max))
```

Punto de corte:
```{r}
(punto.corte <-sapply(perf1@x.values, "[", posicion.max))
```

```{r}
plot(perf1, col = "darkred")
abline(h = 0.9, lty = 2)
abline(v = punto.corte, lty = 2)
```

### f) Cuantifica la capacidad predictiva del modelo en el conjunto de entrenamiento.
```{r}
pred.modelo.stp <-prediction(fitted.values(modelo.stp), df$complication)
perf.modelo.stp <-performance(pred.modelo.stp, "tpr", "fpr")
AUC.modelo.stp <-performance(pred.modelo.stp, "auc")
AUC.modelo.stp@y.values
```

Vemos que el modelo tiene ua capacidad predictiva del 82%. 




##  Modelo definitivo.

### a) Presentación de la ecuación del modelo en términos de logits, de odds y de probabilidad.

```{r}
summary(modelo1)
```
The coefficients displayed are for logits, just as in your example. If we plot these data and this model, we see the sigmoidal function that is characteristic of a logistic model fit to binomial data


```{r}
modelo.stp
```


### b) Interpretación de los coeficientes del modelo: factores de riesgo y factores protectores.




##  Diagnóstico de residuos gráficamente. Razonar si existen deficiencias en el modelo






## Evaluación del modelo en el conjunto de test (20 % de los df que has dejado aparte anteriormente).

### a) Usando el modelo ajustado, clasificar los individuos del conjunto de test en las clases Y = 0 o Y = 1. Usar la probabilidad de corte óptima, $p_{opt}$  calculada anteriormente.



### b) Construir la tabla de clasificación para el conjunto test − set. Valorar el resultado.